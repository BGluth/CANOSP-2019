{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulations and analysis\n",
    "\n",
    "In this notebook, we assess the performance of FL and FL with DP relative to baseline models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from mozfldp.client import Client\n",
    "from mozfldp.model import SGDModel\n",
    "#from mozfldp.server import ServerFacade\n",
    "from mozfldp.simulation_runner import FLSimulationRunner, SGDSimulationRunner\n",
    "\n",
    "# auto-reload the modules everytime a cell is run\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_from_file(csv_file):\n",
    "    \"\"\"Returns the dataset as a pandas DataFrame. \"\"\"\n",
    "    return pd.read_csv(csv_file)\n",
    "\n",
    "\n",
    "def get_dataset_characteristics(df, label_col=\"label\", user_id_col=\"user_id\"):\n",
    "    feature_cols = df.drop(columns=[label_col, user_id_col]).columns\n",
    "    class_labels = df[label_col].unique()\n",
    "    return {\n",
    "        \"n\": len(df),\n",
    "        \"num_features\": len(feature_cols),\n",
    "        \"num_classes\": len(class_labels),\n",
    "        \"num_users\": df[user_id_col].nunique(),\n",
    "        \"feature_cols\": feature_cols,\n",
    "        \"class_labels\": class_labels\n",
    "    }\n",
    "\n",
    "def summarize_dataset(df, df_info):\n",
    "    display(df.head())\n",
    "    print(\"\\nNum training examples: {:,}\".format(df_info[\"n\"]))\n",
    "    print(\"Num features: {:,}\".format(df_info[\"num_features\"]))\n",
    "    print(\"Num classes: {:,}\".format(df_info[\"num_classes\"]))\n",
    "    print(\"Num users: {:,}\".format(df_info[\"num_users\"]))\n",
    "    \n",
    "    print(\"\\nLabels:\")\n",
    "    _ = (\n",
    "        dataset_blob\n",
    "        .groupby(\"label\")\n",
    "        .size()\n",
    "        .plot.barh(\n",
    "            legend=False,\n",
    "            title=\"Num examples per label\"\n",
    "        )\n",
    "    )\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Users:\")\n",
    "    _ = (\n",
    "        dataset_blob\n",
    "        .groupby([\"user_id\", \"label\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"n_examples\")\n",
    "        .pivot(\"user_id\", \"label\", \"n_examples\")\n",
    "        .plot.bar(\n",
    "            stacked=True,\n",
    "            title=\"Distribution of training examples per user\",\n",
    "            figsize=(20, 8)\n",
    "        )\n",
    "    )\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Features:\")\n",
    "    dataset_blob.hist(\n",
    "        column=df_info[\"feature_cols\"],\n",
    "        bins=50,\n",
    "        figsize=(20, 10),\n",
    "        sharex=True\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, initialize the various components to be used in running simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOB_DATASET_PATH = \"../datasets/blob_S20000_L3_F4_U100.csv\"\n",
    "TEST_DATA_PROP = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We begin with the \"blob\" dataset, a randomly generated dataset containing all numerical features grouped into meaningful labelled clusters. A baseline predictive model should perform very well on this data. Indiviual training examples were allocated across users unifomrly at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_blob = load_dataset_from_file(BLOB_DATASET_PATH)\n",
    "dataset_info = get_dataset_characteristics(dataset_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_dataset(dataset_blob, dataset_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test split\n",
    "\n",
    "Split the dataset by sampling users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_test = np.random.choice(\n",
    "    dataset_blob[\"user_id\"].unique(),\n",
    "    size = int(dataset_info[\"num_users\"] * TEST_DATA_PROP),\n",
    "    replace=False\n",
    ")\n",
    "\n",
    "dataset_test = dataset_blob[dataset_blob[\"user_id\"].isin(users_test)]\n",
    "dataset_train = dataset_blob[~dataset_blob[\"user_id\"].isin(users_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num training examples: {:,}\".format(len(dataset_train)))\n",
    "print(\"Num testing examples: {:,}\".format(len(dataset_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize\n",
    "\n",
    "Center and scale the features to unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(dataset_train[dataset_info[\"feature_cols\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [dataset_train, dataset_test]:\n",
    "    df.loc[:, dataset_info[\"feature_cols\"]] = scaler.transform(df.loc[:, dataset_info[\"feature_cols\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature means: {}\".format(scaler.mean_))\n",
    "print(\"Feature standard devs: {}\".format(scaler.scale_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Start with a linear SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_model = SGDModel(\n",
    "    loss=\"hinge\",\n",
    "    # shuffling shouldn't matter using our minibatch approach, but just in case\n",
    "    shuffle=False,\n",
    "    # default learning rate decays with the number of iterations\n",
    "    learning_rate=\"optimal\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial weights\n",
    "\n",
    "Select initial model weights uniformly at random from the square with side [-1, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_initial_weights(dataset_info, range_max=1):\n",
    "    nrows = dataset_info[\"num_classes\"]\n",
    "    # Special case for 2 classes: single weight vector.\n",
    "    if nrows == 2:\n",
    "        nrows = 1\n",
    "    init_weights = np.random.random_sample((nrows, dataset_info[\"num_features\"] + 1))\n",
    "    return init_weights[:, :-1], init_weights[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_coef, init_intercept = select_initial_weights(dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initial coefs\")\n",
    "print(init_coef)\n",
    "print(\"\\nInitial intercept\")\n",
    "print(init_intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "Through the simulations we compare Federated Learning to the standard non-federated approach to training the model above.\n",
    "\n",
    "Model training is performed by iterating through a number of communication rounds. In the federated context, each communication round retrieves model updates across all users and averages them centrally. The non-federated approach doesn't involve a concept of communication rounds beyond training epochs (dataset passes). For the purposes of comparison, a non-federated communication round is considered to be a fixed number of epochs.\n",
    "\n",
    "Comparions are made across combinations of the following parameters:\n",
    "\n",
    "- `num_epochs`: Number of passes over the training data (training epochs) in each communication round.\n",
    "    * FL: the number of passes each client makes over its training data prior to central averaging\n",
    "    * non-FL: the number of passes over the dataset considered as a \"round\"\n",
    "\n",
    "\n",
    "- `batch_size`: Target number of training examples included per weight update (gradient descent step), aka \"minibatch\". Data is allocated to batches uniformly at random. Actual batch sizes may be smaller, eg. if the dataset doesn't divide evenly into batches of this size. Standard SGD uses a `batch_size` of 1, and full-batch GD uses $\\infty$.\n",
    "    * FL: batching is done separately on each client's dataset.\n",
    "    * non-FL: batching is applied across the entire dataset.\n",
    "\n",
    "\n",
    "- `client_fraction`: Proportion of clients whose data is included in each communication round.\n",
    "    * non-FL: as the data is not considered split by client, the fraction is essentially 1. However, we could consider pooling all the data from a fraction of clients for experimental purposes.\n",
    "    \n",
    "\n",
    "- `sensitivity`: (FLDP) the maximal size of a single weight update (GD step), ie. for a single client batch, in terms of vector norm.\n",
    "\n",
    "\n",
    "- `noise_scale`: (FLDP) parameter controlling the tradeoff between the noise applied in each communication round and the allowable number of training rounds falling within privacy budget.\n",
    "\n",
    "\n",
    "- `user_weight_cap`: (FLDP) limit on the influence of a single user's weight update in the federated average. A higher limit requires more noise to be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"num_epochs\": 1,\n",
    "    \"batch_size\": 10,\n",
    "    \"client_fraction\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test this out with a reduced dataset temporarily.\n",
    "\n",
    "users_reduced = np.random.choice(\n",
    "    dataset_train[\"user_id\"].unique(),\n",
    "    size = 20,\n",
    "    replace=False\n",
    ")\n",
    "dataset_reduced = dataset_train[dataset_train[\"user_id\"].isin(users_reduced)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_sgd = SGDSimulationRunner(\n",
    "    num_epochs=model_params[\"num_epochs\"],\n",
    "    batch_size=model_params[\"batch_size\"],\n",
    "    model=sgd_model,\n",
    "    training_data=dataset_reduced,\n",
    "        #dataset_train,\n",
    "    coef_init=init_coef,\n",
    "    intercept_init=init_intercept\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_fl = FLSimulationRunner(\n",
    "    num_epochs=model_params[\"num_epochs\"],\n",
    "    batch_size=model_params[\"batch_size\"],\n",
    "    client_fraction=model_params[\"client_fraction\"],\n",
    "    model=sgd_model,\n",
    "    training_data=dataset_reduced,\n",
    "        #dataset_train,\n",
    "    coef_init=init_coef,\n",
    "    intercept_init=init_intercept\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval = sgd_model.get_clone()\n",
    "model_eval.set_training_classes(dataset_train[\"label\"])\n",
    "\n",
    "def compute_accuracy(coef, intercept):\n",
    "    model_eval.set_weights(coef, intercept)\n",
    "    return model_eval.classifier.score(\n",
    "        dataset_test[dataset_info[\"feature_cols\"]],\n",
    "        dataset_test[\"label\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ROUNDS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_sgd = []\n",
    "acc_fl = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(NUM_ROUNDS):\n",
    "    coef, intercept = sim_sgd.run_simulation_round()\n",
    "    acc_sgd.append(compute_accuracy(coef, intercept))\n",
    "    coef, intercept = sim_fl.run_simulation_round()\n",
    "    acc_fl.append(compute_accuracy(coef, intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_fl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
