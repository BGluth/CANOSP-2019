{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OsHSQ1TEXDNZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "from mozfldp.simulation_util import client_update\n",
    "import warnings\n",
    "\n",
    "# hide the warning message temporarily\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# auto-reload the modules everytime a cell is run\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RfZrf09ZofuP"
   },
   "source": [
    "## Client Update Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "fZj9flYHXNd4",
    "outputId": "09beecb0-cd45-46d6-9932-77cef46d5044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[28.48292577,  0.        ,  0.        ]]), array([-9.])]\n"
     ]
    }
   ],
   "source": [
    "# this data will be provided by the server\n",
    "features = [[1, 4, 3], [0, 2, 2], [1, 4, 0], [0, 5, 3], [1, 2, 1], [0, 2, 9]]\n",
    "labels = [1, 0, 1, 0, 1, 0]\n",
    "\n",
    "coefs = np.array([29., 0., 0.]) # should be of size num_classes * num_features\n",
    "intercepts = np.array([-9])\n",
    "weights = [coefs, intercepts]\n",
    "\n",
    "epochs = 3\n",
    "batch_size = 3\n",
    "\n",
    "new_weights = client_update(weights, epochs, batch_size, features, labels)\n",
    "print(new_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Server Update Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Weights:  [[ 9.21039435  3.42478697 10.5526031 ]] [-0.50832144]\n",
      "Updated Weights:  [[-12.39387656  -2.63282931  10.92549293]] [-30.23488422]\n",
      "Updated Weights:  [[-0.39884221  3.05007116  1.63993618]] [6.87589235]\n",
      "Updated Weights:  [[-10.58692427   7.21644198   4.20351571]] [-3.3782652]\n",
      "Updated Weights:  [[1.68096538 4.17314952 3.80210084]] [-27.61753893]\n",
      "Updated Weights:  [[1.86070607 2.39630708 5.12672219]] [-3.18491918]\n",
      "Updated Weights:  [[ -3.83699408 -14.42908596  -3.41825447]] [-13.95188863]\n",
      "Updated Weights:  [[ 7.77314372 -6.5005065  -4.40597068]] [-38.14942825]\n",
      "Updated Weights:  [[10.63308565 -1.27519038  3.92540565]] [-14.12513733]\n",
      "Updated Weights:  [[0.15083477 1.50987645 6.76575981]] [-18.83791491]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mozfldp.simulation_util import server_update\n",
    "\n",
    "init_weights = [np.array([0, 0, 0]), np.array([0])]\n",
    "client_fraction = 0.5\n",
    "num_rounds = 10\n",
    "epoch = 10\n",
    "batch_size = 25\n",
    "display_weight_per_round = True\n",
    "\n",
    "num_client = 100\n",
    "samples_per_client = 100\n",
    "num_features = 3\n",
    "features = np.random.randint(10, size=(num_client, samples_per_client, num_features))\n",
    "labels = np.random.randint(2, size=(num_client, samples_per_client))\n",
    "\n",
    "new_clf = server_update(init_weights, client_fraction, num_rounds, features, labels, epoch, batch_size, display_weight_per_round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Params:  {'batch_size': 40, 'client_fraction': 1, 'epoch': 1, 'init_weight': [array([[0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.]]), array([0., 0., 0.])], 'num_rounds': 10}\n",
      "Weights: [array([[ 14.57954214,   5.17006556,  31.56363127,  -9.96949121],\n",
      "       [ -4.69985766,   1.515726  ,  11.90157783, -16.37977076],\n",
      "       [  9.99352147,  22.11192303,  13.81040962, -16.5691806 ]]), array([-259.50851682, -251.06849701, -276.58063764])]\n",
      "Score: 0.328250\n",
      "\n",
      "\n",
      "Training...\n",
      "Params:  {'batch_size': 40, 'client_fraction': 1, 'epoch': 5, 'init_weight': [array([[0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.]]), array([0., 0., 0.])], 'num_rounds': 10}\n",
      "Weights: [array([[ 14.93429043,   6.54932159,  27.45016802, -12.41496433],\n",
      "       [  3.38199928,  18.17709668,  23.4173894 ,  -9.74048276],\n",
      "       [  1.66314514,  22.51783106,  18.47015954, -14.83775359]]), array([-263.28207476, -281.25648769, -282.83460913])]\n",
      "Score: 0.338250\n",
      "\n",
      "\n",
      "Training...\n",
      "Params:  {'batch_size': 40, 'client_fraction': 0.1, 'epoch': 1, 'init_weight': [array([[0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.]]), array([0., 0., 0.])], 'num_rounds': 10}\n",
      "Weights: [array([[ 26.75906765,  -7.34123966,  10.60268656,  -8.65601973],\n",
      "       [ 33.64875359,   2.04387534,  44.91846441,   6.12015676],\n",
      "       [ 20.41021515,  28.17448108, -25.89890721,  25.77850835]]), array([-272.87852689, -263.08917925, -221.32365134])]\n",
      "Score: 0.335750\n",
      "\n",
      "\n",
      "Training...\n",
      "Params:  {'batch_size': 40, 'client_fraction': 0.1, 'epoch': 5, 'init_weight': [array([[0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.]]), array([0., 0., 0.])], 'num_rounds': 10}\n",
      "Weights: [array([[ 19.44251742,  31.59622758,  32.30731436,   0.60587585],\n",
      "       [  5.66561972, -14.99280475,  14.47962409, -33.39068466],\n",
      "       [ 16.06971136,  -4.10546164,   0.12570958, -56.11560999]]), array([-259.45876218, -300.26555504, -192.89618956])]\n",
      "Score: 0.331875\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid, train_test_split\n",
    "from mozfldp.simulation_util import server_update\n",
    "import numpy as np\n",
    "import mozfldp.random_data_gen as rdata_gen\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "NUM_SAMPLES = 20000\n",
    "NUM_LABELS = 3\n",
    "NUM_FEATURES = 4\n",
    "NUM_CLIENTS = 100\n",
    "g_prms = rdata_gen.InputGenParams(NUM_SAMPLES, NUM_LABELS, NUM_FEATURES, NUM_CLIENTS)\n",
    "df = pd.read_csv(\"datasets/blob_S20000_L3_F4_U100.csv\")\n",
    "\n",
    "sim_labels, sim_features = rdata_gen.transform_data_for_simulator_format(df, g_prms)\n",
    "features = np.array(sim_features)\n",
    "labels = np.array(sim_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=0)\n",
    "\n",
    "init_weights = np.zeros((NUM_LABELS, NUM_FEATURES), dtype=np.float64, order=\"C\")\n",
    "init_intercept = np.zeros(NUM_LABELS, dtype=np.float64, order=\"C\")\n",
    "\n",
    "# Find all the permutations of the parameters\n",
    "param_grid = {\"client_fraction\": [1, 0.1],\n",
    "              \"epoch\": [1, 5],\n",
    "              \"batch_size\": [40], # TODO: need to implement an infinite batch size\n",
    "              \"init_weight\": [[init_weights, init_intercept]],\n",
    "              \"num_rounds\": [10]}\n",
    "\n",
    "# run training/testing over all parameter combinations to get the best combination\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(\"Training...\")\n",
    "    print(\"Params: \", params)\n",
    "    classifier = server_update(params[\"init_weight\"], params[\"client_fraction\"], params[\"num_rounds\"], X_train, y_train, params[\"epoch\"], params[\"batch_size\"], False)\n",
    "    weights = [classifier.coef_, classifier.intercept_]\n",
    "\n",
    "    # need to remove the client dimension from our data for testing \n",
    "    # ex: [[[1, 1], [2, 2]], [[3, 3], [4, 4]]] needs to become [[1, 1], [2, 2], [3, 3], [4, 4]] for features \n",
    "    # and [[1, 2], [3, 4]] needs to become [1, 2, 3, 4] for labels \n",
    "    reshaped_X_test = np.reshape(X_test, (X_test.shape[0] * X_test.shape[1], X_test.shape[2]))\n",
    "    reshaped_y_test = np.reshape(y_test, y_test.size)\n",
    "    \n",
    "    score = classifier.score(reshaped_X_test, reshaped_y_test)\n",
    "\n",
    "    print('Weights: {}\\nScore: {:f}\\n\\n'.format(weights, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Federated Learning Simulation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
