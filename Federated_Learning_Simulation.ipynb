{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "OsHSQ1TEXDNZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RfZrf09ZofuP"
   },
   "source": [
    "## Client Update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "fZj9flYHXNd4",
    "outputId": "09beecb0-cd45-46d6-9932-77cef46d5044",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  [[[1, 4, 3], [0, 2, 2], [1, 4, 0]], [[0, 5, 3], [1, 2, 1], [0, 2, 9]]]\n",
      "Labels:  [[1, 0, 1], [0, 1, 0]]\n",
      "[[1, 4, 3], [0, 2, 2], [1, 4, 0]] [1, 0, 1] [29.0, 0.0, 0.0, -9]\n",
      "[[0, 5, 3], [1, 2, 1], [0, 2, 9]] [0, 1, 0] [28.91317365  0.          0.         -9.        ]\n",
      "[[1, 4, 3], [0, 2, 2], [1, 4, 0]] [1, 0, 1] [28.82660726  0.          0.         -9.        ]\n",
      "[[0, 5, 3], [1, 2, 1], [0, 2, 9]] [0, 1, 0] [28.74030006  0.          0.         -9.        ]\n",
      "[[1, 4, 3], [0, 2, 2], [1, 4, 0]] [1, 0, 1] [28.65425125  0.          0.         -9.        ]\n",
      "[[0, 5, 3], [1, 2, 1], [0, 2, 9]] [0, 1, 0] [28.56846008  0.          0.         -9.        ]\n",
      "[28.48292577  0.          0.         -9.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "def client_update(init_weights, epochs, batch_size, features, labels):\n",
    "    \"\"\"\n",
    "    Given the previous weights from the server, it does updates on the model\n",
    "    and returns the new set of weights\n",
    "\n",
    "    init_weights: weights to initialize the training with \n",
    "        ex: [coef1, coef2, ..., coefn, intercept]\n",
    "    epochs: number of epochs to run the training for \n",
    "    batch_size: the size of each batch of data while training \n",
    "    features: a 2D array containing features for each sample \n",
    "        ex: [[feature1, feature2], [feature1, feature2], ...]\n",
    "    label: an array containing the labels for the corresponding sample in \"features\"\n",
    "        ex: [label1, label2, ...]\n",
    "    \"\"\"\n",
    "    \n",
    "    # split the data into batches by given batch_size\n",
    "    # TODO: need to ensure that a batch doesn't just contain 1 label\n",
    "    batches_features = []\n",
    "    batches_labels = []\n",
    "    \n",
    "    for i in range(0, len(features), batch_size):\n",
    "      batches_features.append(features[i:i + batch_size])\n",
    "      batches_labels.append(labels[i:i + batch_size])\n",
    "      # TODO: merge the features and labels into one tuple?\n",
    "    \n",
    "    print(\"Features: \", batches_features)\n",
    "    print(\"Labels: \", batches_labels)\n",
    "\n",
    "    weights = list(init_weights)\n",
    "    \n",
    "    # set max_iter to 1 so that each .fit() call only does one training step\n",
    "    classifier = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=1)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(len(batches_features)):\n",
    "            print(batches_features[i], batches_labels[i], weights)\n",
    "            \n",
    "            classifier.fit(batches_features[i],\n",
    "                           batches_labels[i],\n",
    "                           coef_init=weights[:-1],\n",
    "                           intercept_init=weights[-1])\n",
    "            \n",
    "            # update the weights so for the next batch the new ones are used\n",
    "            weights = np.append(classifier.coef_[0], classifier.intercept_)\n",
    "            \n",
    "    return weights\n",
    "\n",
    "# Example usage\n",
    "\n",
    "# this data will be provided by the server\n",
    "features = [[1, 4, 3], [0, 2, 2], [1, 4, 0], [0, 5, 3], [1, 2, 1], [0, 2, 9]]\n",
    "labels = [1, 0, 1, 0, 1, 0]\n",
    "weights = [29., 0., 0., -9]\n",
    "epochs = 3\n",
    "batch_size = 3\n",
    "\n",
    "new_weights = client_update(weights, epochs, batch_size, features, labels)\n",
    "print(new_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Server Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# load data\n",
    "\n",
    "clients = 10\n",
    "data_number = 30\n",
    "features = np.random.randint(10,size=(clients,data_number,3))\n",
    "labels = np.random.randint(2,size=(100,30))\n",
    "epoch = 10\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def append(list, element):\n",
    "    \"\"\"\n",
    "    helper function to append array into array in numpy\n",
    "    \"\"\"\n",
    "    return np.concatenate((list, [element])) if list is not None else [element]\n",
    "\n",
    "def server():\n",
    "    \n",
    "    \"\"\"\n",
    "    Calls clientUpdate to get the updated weights from clients, and applies Federated\n",
    "    Averaging Algorithm to update the weight on server side\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # initialize the weight\n",
    "    w = [0,0,0,0]\n",
    "    # number of clients\n",
    "    K = 10\n",
    "    # fraction of clients\n",
    "    C = 0.5\n",
    "    # number of rounds run on the server\n",
    "    round_num = 10\n",
    "\n",
    "    # use to generate n_k so that the sum of n_k equals to n\n",
    "\n",
    "    for i in range(round_num):\n",
    "        # calculate the number of clients used in this round\n",
    "        m = max(int(K*C),1)\n",
    "        # random set of m clients\n",
    "        S = np.array(random.sample(range(clients), clients))\n",
    "        \n",
    "        num_samples = []\n",
    "            \n",
    "        # grab all the weights from clients\n",
    "        client_weights = None   \n",
    "        for i in S:\n",
    "            client_feature = features[i]\n",
    "            client_label = labels[i]\n",
    "            client_w = np.random.randint(low = 0, high = 10, size=4)\n",
    "            client_weights = append(client_weights,client_w)\n",
    "            \n",
    "            num_samples.append(len(client_feature))\n",
    "\n",
    "        # calculate the new server weight based on new weights coming from client\n",
    "        new_w = np.zeros(4)\n",
    "        for i in range(len(client_weights)):\n",
    "            current_weight = client_weights[i]\n",
    "            n_k = len(features[i])\n",
    "            added_w = [value*(n_k)/sum(num_samples) for value in current_weight]\n",
    "            new_w = np.add(new_w,added_w)\n",
    "        \n",
    "        # update the server weight to newly calculated weight\n",
    "        w = new_w\n",
    "        print(w)\n",
    "        \n",
    "server()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Federated Learning Simulation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
